{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Models:\n",
    "\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- Decision Tress\n",
    "- Random Forest\n",
    "- Gradient Boosting Machine\n",
    "- ANN\n",
    "- KNN\n",
    "- Naive Bayes\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "En este python, se aplicaran los modelos a traves de una pipeline. De este modo se odra aplicar una pipeline de preprocesamiento que incluya eliminacion de valores nulos, normalizacion y algunos modelos de feature selection, de este modo podemos rapidamente aplicar distintoas fases.\n",
    "\n",
    "\n",
    "**REMEMBER: BECAUSE WE ARE DOING A PIPELINE FOR PREPROCESSING, IF WE ARE GOING TO IMPUTE MISSING VALUES OR NORMALIZE THE DATA, THE MODEL HAS TO BE TRAIN WITH THE TRAINING SET AND THE TRAIN-TEST SET (BOTH) HAVE TO BE TRANSFORM** - **DO THE TEST TRANSFORMATION BEFORE THE EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASIC MODEL APPLICATION\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('impute', IterativeImputer(random_state = 42)), # substitude the null values: mean\n",
    "    ('scaler', StandardScaler())                     # to normalize the data\n",
    "                                                     # you can add feature selection like PCA here\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(100483869) # reproducibility\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Put together model\n",
    "model_p = Pipeline ([\n",
    "    ( 'preprocessor', pipeline ),\n",
    "    ('classifier', model)])\n",
    "\n",
    "LR_model = model_p.fit(X=X_train0, y=y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLEX MODEL\n",
    "# In case we want to add hyperparameter tuning and Cross-validation we can add it like this, \n",
    "# we have to add it to the basic model without the previoud fit - \n",
    "# WE HAVE TO ERASE LINE: LR_model = model_p.fit(X=X_train0, y=y_train0)\n",
    "\n",
    "\n",
    "#### HYPER-PARAMETERS  #######\n",
    "# ranges for gamma and C\n",
    "param_grid = {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100],\n",
    "        'classifier__max_iter': [100, 1000, 10000]}\n",
    "\n",
    "# Inner CV\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=100483869)\n",
    "\n",
    "\n",
    "# instantiation of the grid of hyperparameters that will be searched with cross validation\n",
    "\n",
    "grid_search = GridSearchCV(LR_model, #model\n",
    "                   param_grid, # rango of value of the hyper-parameter to evaluate\n",
    "                   scoring='f1',\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1,\n",
    "                   verbose=3) #-1 means use all processors\n",
    "\n",
    "\n",
    "\n",
    "#START OF THE RECORD\n",
    "LR_model_grid = grid_search.fit(X=X_train0, y=y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASIC MODEL APPLICATION\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('impute', IterativeImputer(random_state = 42)), # substitude the null values: mean\n",
    "    ('scaler', StandardScaler())                     # to normalize the data\n",
    "                                                     # you can add feature selection like PCA here\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(100483869) # reproducibility\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic regression model\n",
    "model = SVC()\n",
    "\n",
    "# Put together model\n",
    "model_p = Pipeline ([\n",
    "    ( 'preprocessor', pipeline ),\n",
    "    ('classifier', model)])\n",
    "\n",
    "SVM_model = model_p.fit(X=X_train0, y=y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLEX MODEL\n",
    "# In case we want to add hyperparameter tuning and Cross-validation we can add it like this, \n",
    "# we have to add it to the basic model without the previoud fit - \n",
    "# WE HAVE TO ERASE LINE: SVM_model = model_p.fit(X=X_train0, y=y_train0)\n",
    "\n",
    "\n",
    "#### HYPER-PARAMETERS  #######\n",
    "# Search space of SVM hyperparameters\n",
    "v_gamma = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "v_C = [0.001,.01, .1, 1, 10, 100, 1000]\n",
    "# Grid of hyperparameters\n",
    "param_grid = [\n",
    "  {'classifier__C': v_C,\n",
    "   'classifier__gamma': v_gamma,\n",
    "   'classifier__kernel': ['rbf']},\n",
    "  ]\n",
    "\n",
    "# Inner CV\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=100483869)\n",
    "\n",
    "\n",
    "# instantiation of the grid of hyperparameters that will be searched with cross validation\n",
    "\n",
    "grid_search = GridSearchCV(SVM_model, #model\n",
    "                   param_grid, # rango of value of the hyper-parameter to evaluate\n",
    "                   scoring='f1',\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1,\n",
    "                   verbose=2) #-1 means use all processors\n",
    "\n",
    "\n",
    "\n",
    "#START OF THE RECORD\n",
    "SVM_model_grid = grid_search.fit(X=X_train0, y=y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
