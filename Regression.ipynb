{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Models:\n",
    "\n",
    "- Linear Regression\n",
    "- Polynomial Regression\n",
    "- Decision Tree Regression\n",
    "- Support Vector Regression\n",
    "- Lasso Regression\n",
    "- Random Forest Regression\n",
    "- Neural Network Regression  \n",
    "- KNN\n",
    "- SVM\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLEX MODEL\n",
    "# In case we want to add hyperparameter tuning and Cross-validation we can add it like this, \n",
    "# we have to add it to the basic model without the previoud fit - \n",
    "# WE HAVE TO ERASE LINE: LR_model = model_p.fit(X=X_train0, y=y_train0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True, normalize=False)  # these are the hyperparameters\n",
    "\n",
    "model_p = Pipeline ([\n",
    "    ( 'preprocessor', pipeline ),\n",
    "    ('classifier', model)])\n",
    "\n",
    "\n",
    "# Inner CV\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=100483869)\n",
    "\n",
    "\n",
    "# instantiation of the grid of hyperparameters that will be searched with cross validation\n",
    "\n",
    "grid_search = GridSearchCV(model_p, #model\n",
    "                   param_grid, # rango of value of the hyper-parameter to evaluate\n",
    "                   scoring='f1',\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1,\n",
    "                   verbose=3) #-1 means use all processors\n",
    "\n",
    "\n",
    "\n",
    "#START OF THE RECORD\n",
    "model_grid = grid_search.fit(X=X_train0, y=y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLEX MODEL\n",
    "# In case we want to add hyperparameter tuning and Cross-validation we can add it like this, \n",
    "# we have to add it to the basic model without the previoud fit - \n",
    "# WE HAVE TO ERASE LINE: LR_model = model_p.fit(X=X_train0, y=y_train0)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())   #these are the hyperparameters\n",
    "\n",
    "model_p = Pipeline ([\n",
    "    ( 'preprocessor', pipeline ),\n",
    "    ('classifier', model)])\n",
    "\n",
    "\n",
    "# Inner CV\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=100483869)\n",
    "\n",
    "\n",
    "# instantiation of the grid of hyperparameters that will be searched with cross validation\n",
    "\n",
    "grid_search = GridSearchCV(model_p, #model\n",
    "                   param_grid, # rango of value of the hyper-parameter to evaluate\n",
    "                   scoring='f1',\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1,\n",
    "                   verbose=3) #-1 means use all processors\n",
    "\n",
    "\n",
    "\n",
    "#START OF THE RECORD\n",
    "model_grid = grid_search.fit(X=X_train0, y=y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EVALUATION FOR A REGRESSION METHOD ##\n",
    "\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_decisiontree)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred_decisiontree)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Coefficient of Determination (R²)\n",
    "r2 = r2_score(y_test, y_pred_decisiontree)\n",
    "print(\"Coefficient of Determination (R²):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred_decisiontree)\n",
    "mse = mean_squared_error(y_test, y_pred_decisiontree)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_decisiontree)\n",
    "\n",
    "# Create a table\n",
    "table = [[\"Mean Absolute Error (MAE)\", mae],\n",
    "         [\"Mean Squared Error (MSE)\", mse],\n",
    "         [\"Root Mean Squared Error (RMSE)\", rmse],\n",
    "         [\"Coefficient of Determination (R²)\", r2]]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual vs Predicted graph\n",
    "\n",
    "From scatter plots of Actual vs Predicted You can tell how well the model is performing. For Ideal model, the points should be closer to a diagonal line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of residual\n",
    "One of the assumption in Linear regression is that the residual should be normally distributed, if your model’s residual is not normally distributed it will not have a bell shaped curve which indicates that your model is not bias and in this case for your dateset regression may not be an appropriate choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual vs. Fitted Values Plot\n",
    "\n",
    "In this scatter plot the y axis represents residuals and the x axis represented fitted values or predicted value. This plot is used to detect non-linearity, unequal error variances, and outliers in the model.\n",
    "\n",
    "For Ideal model, this plot is not supposed to show any pattern. But if any pattern is visible such as curve, U shape then it indicates that there is non-linearity in the data set. (heteroskedasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality Q-Q Plot\n",
    "This plot is used to determine the normal distribution of errors.\n",
    "For normally distributed data, observations should lie approximately on a straight line. If the data is non-normal, the points form a curve deviating from a straight line which is a problematic situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals vs Leverage\n",
    "\n",
    "This plot can be helpful in finding influential cases if there’s any. Not all outliers (having huge values) are influential in linear regression , some cases could be very influential even if they have value within a reasonable range. So removing or excluding these values can change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
