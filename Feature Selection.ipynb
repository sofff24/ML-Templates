{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vif\n",
    "\n",
    "Vif realiza una selección de características basada en el VIF para eliminar características con alta multicolinealidad, lo que ayuda a mejorar la calidad de los modelos de aprendizaje automático al reducir la redundancia entre las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "\n",
    "class Vif(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "      X_train = X.copy()\n",
    "      self.dele = []\n",
    "\n",
    "      while True:\n",
    "          VIF = np.array([variance_inflation_factor(X_train, i) for i in range(X_train.shape[1])])\n",
    "\n",
    "          # delete the maximum one and repeat the count until the maximum value is lower than 5.\n",
    "          self.dele.append(np.argmax(VIF))\n",
    "          X_train = np.delete(X_train, self.dele[-1], axis=1)\n",
    "          if np.max(VIF) < 5:\n",
    "              break\n",
    "\n",
    "      return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.delete(X, self.dele, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vif2\n",
    "\n",
    "Vif2 realiza una selección de características basada en el VIF para eliminar características con alta multicolinealidad, lo que ayuda a mejorar la calidad de los modelos de aprendizaje automático al reducir la redundancia entre las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np \n",
    "\n",
    "class Vif2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.dele = []\n",
    "        for _ in range(X.shape[1]):\n",
    "            vif = np.zeros(X.shape[1])\n",
    "            for i in range(X.shape[1]):\n",
    "                    if i in self.dele:\n",
    "                        continue\n",
    "                    vif[i] = variance_inflation_factor(X, i)\n",
    "\n",
    "            # delete the maximum one and repeat the count until the maximum value is lower than 5.\n",
    "            amax  = vif.argmax()\n",
    "            if vif[amax] < 5:\n",
    "                break\n",
    "            self.dele.append(amax)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.delete(X, self.dele, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferencia entre Vif y Vif2:\n",
    "\n",
    "Ambas clases, Vif y Vif2, tienen el mismo propósito: realizar una selección de características basada en el factor de inflación de la varianza (VIF) para eliminar características altamente multicolineales. Sin embargo, difieren en su implementación interna:\n",
    "\n",
    "- Iteración:\n",
    "\n",
    "    Vif: Utiliza un bucle while para iterar y eliminar características con un VIF superior al umbral definido (5) hasta que todas las características restantes tengan un VIF inferior al umbral.\n",
    "\n",
    "    Vif2: Utiliza un bucle for anidado para calcular el VIF de cada característica individualmente y elimina la característica con el VIF más alto en cada iteración hasta que todas las características restantes tengan un VIF inferior al umbral.\n",
    "\n",
    "- Manipulación de datos:\n",
    "\n",
    "    Vif: Crea una copia de los datos de entrada X y luego realiza eliminaciones en esta copia a medida que se eliminan las características con alto VIF.\n",
    "\n",
    "    Vif2: Utiliza la matriz X original para calcular el VIF y luego elimina características de la matriz original.\n",
    "\n",
    "- Estructura de la clase:\n",
    "\n",
    "    Ambas clases implementan las interfaces BaseEstimator y TransformerMixin, lo que les permite ser utilizadas como estimadores y transformadores en scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Correlation realiza una selección de características basada en la significancia estadística de las diferencias entre las muestras de las clases 0 y 1 utilizando la prueba de ANOVA. Las características que no cumplen con un cierto umbral de significancia estadística se eliminan del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "class Correlation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "      X_train = X.copy()\n",
    "      y_train = y.copy()\n",
    "\n",
    "      self.dele = []\n",
    "      for i in range(X_train.shape[1]):\n",
    "        AnovaResults = f_oneway(X_train[y_train == 0, i], X_train[y_train == 1, i])\n",
    "\n",
    "        if AnovaResults[1] > self.alpha:\n",
    "          self.dele.append(i)\n",
    "\n",
    "\n",
    "      return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.delete(X, self.dele, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation2\n",
    "\n",
    "Correlation2 se utiliza para realizar una selección de características basada en la significancia estadística de las diferencias entre las características para diferentes clases de la variable objetivo utilizando la prueba de ANOVA. Las características que no cumplen con un cierto umbral de significancia estadística se eliminan del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Correlation2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        _, a_p      = f_oneway(X[y == 0, :], X[y == 1, :])\n",
    "        self.dele   = np.flatnonzero(a_p > self.alpha)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.delete(X, self.dele, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferencias entre Correlation y Correlation2:\n",
    "\n",
    "\n",
    "- Método de selección de características:\n",
    "\n",
    "    Correlation: Utiliza el método ANOVA (Análisis de varianza) para calcular la importancia estadística de cada característica en relación con la variable objetivo. Luego, selecciona las características cuyos valores de p de ANOVA superan un umbral predefinido (alpha) para eliminarlas.\n",
    "\n",
    "    Correlation2: Utiliza una estrategia diferente para calcular la importancia de cada característica en relación con la variable objetivo. Se basa en el método de eliminación iterativa, donde en cada iteración se calcula el VIF (Factor de inflación de la varianza) para cada característica y se elimina la característica con el VIF más alto hasta que ningún VIF sea superior a un umbral predefinido (5).\n",
    "\n",
    "- Manipulación de datos:\n",
    "\n",
    "    Correlation: No modifica directamente los datos de entrada X, sino que utiliza las funciones f_oneway y np.delete para calcular la importancia de las características y eliminar las características seleccionadas.\n",
    "\n",
    "    Correlation2: Modifica los datos de entrada X durante el proceso de ajuste y transformación, eliminando directamente las características con alto VIF.\n",
    "\n",
    "- Estructura de la clase:\n",
    "\n",
    "    Ambas clases implementan las interfaces BaseEstimator y TransformerMixin de scikit-learn, lo que les permite ser utilizadas como estimadores y transformadores en pipelines de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "\n",
    "Esta pipeline es el proceso de feature selection que se debe implementar antes de aplicar los modelos. Aqui se puede especificar el numero de feature selection, podiendo implementar uno o tantos como se quieran y en el orden que se quiera. Anteriormente se han definido funciones especificas pero aqui se especifican mas modelos de feature selection que ya estan implementados y cargados en python como IterativeImputer - para eliminar nulos - o StandardScaler - o PCA.\n",
    "\n",
    "En este ejemplo, como solo estamos hablando de feature selection sobraria los dos primeros metodos, pero por su necesario uso en el origen se dejan para demostracion de como se deberian implementar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PIPELINE ###\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('impute', IterativeImputer(random_state = 42)), #strategy to substitude the null values: mean\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('vif', Vif2()),\n",
    "    ('correlation', Correlation2()),\n",
    "    ('pca', PCA()),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo de la implementacion del pipeline en un modelo seria, utilizando un Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100483869) # reproducibility\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Put together model\n",
    "clf_LR = Pipeline ([\n",
    "    ( 'preprocessor', pipeline ),\n",
    "    ('classifier', model)])\n",
    "\n",
    "clf_LR_grid = clf_LR.fit(X=X_train0, y=y_train0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
